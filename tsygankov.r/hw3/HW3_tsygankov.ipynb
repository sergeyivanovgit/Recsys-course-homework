{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Предсказание вероятности клика на банер FFM\n",
    "\n",
    "\n",
    "Лучше всего показало себя обучение на одном дне. В противном случае модель очень сильно переобучается (это может быть следствие разных причин, например, того, что дни друг от друга сильно отличаются, а у нас данные только за одну неделю).\n",
    "\n",
    "* Модель logreg с фичами взаимодействий и target encoding\n",
    "    * best_params = {'params': {'C': 0.5, 'max_iter': 300, 'random_state': 1}\n",
    "    * test log_loss with best params =  0.13998072945658324\n",
    "* Модель FFM (x-learn):\n",
    "    * best_params = {'epoch': 9, 'k': 10, 'lambda': 0.05, 'lr': 0.01, 'task': 'binary'}\n",
    "    * test log_loss with best params =  0.148402\n",
    "    \n",
    "В итоге видно, что использование FFM из X-learn не дало улучшение в метрике log-loss\n",
    "\n",
    "\n",
    "Есть несколько основных причин: \n",
    "1) слишком мало данных\n",
    "\n",
    "2) не оптимальные гиперпараметры\n",
    "\n",
    "3) нужен более тщательный feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xlearn as xl\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_time</th>\n",
       "      <th>zone_id</th>\n",
       "      <th>banner_id</th>\n",
       "      <th>oaid_hash</th>\n",
       "      <th>campaign_clicks</th>\n",
       "      <th>os_id</th>\n",
       "      <th>country_id</th>\n",
       "      <th>clicks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-09-27 00:01:30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5664530014561852622</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-09-26 22:54:49</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5186611064559013950</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-09-26 23:57:20</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2215519569292448030</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-09-27 00:04:30</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6262169206735077204</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-09-27 00:06:21</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4778985830203613115</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            date_time  zone_id  banner_id            oaid_hash  \\\n",
       "0 2021-09-27 00:01:30        0          0  5664530014561852622   \n",
       "1 2021-09-26 22:54:49        1          1  5186611064559013950   \n",
       "2 2021-09-26 23:57:20        2          2  2215519569292448030   \n",
       "3 2021-09-27 00:04:30        3          3  6262169206735077204   \n",
       "4 2021-09-27 00:06:21        4          4  4778985830203613115   \n",
       "\n",
       "   campaign_clicks  os_id  country_id  clicks  \n",
       "0                0      0           0       1  \n",
       "1                0      0           1       1  \n",
       "2                3      0           0       1  \n",
       "3                0      1           1       1  \n",
       "4                0      1           0       1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_to_use = ['date_time', 'zone_id', 'banner_id', 'oaid_hash', 'campaign_clicks', 'os_id', 'country_id', 'clicks']\n",
    "\n",
    "data = pd.read_csv('../../data/data.csv',\n",
    "                parse_dates=['date_time'], \n",
    "                usecols=cols_to_use\n",
    "                   ,)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sort_values('date_time', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2021-09-26    3102610\n",
       "2021-09-29    2420588\n",
       "2021-09-27    2367303\n",
       "2021-09-28    2307355\n",
       "2021-10-02    2128978\n",
       "2021-09-30    1851189\n",
       "2021-10-01    1643448\n",
       "2021-09-01          1\n",
       "Name: date_time, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.date_time.dt.date.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train on all previous days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process data and Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop 2021-09-01 т.к. есть только один сэмпл с этой датой (outlier)\n",
    "data = data[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    get time features\n",
    "    \"\"\"\n",
    "    df['hour'] = df['date_time'].dt.hour\n",
    "    return df\n",
    "\n",
    "\n",
    "def featurize_pipeline(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    pipeline for the feature preparation\n",
    "    \"\"\"\n",
    "    featurized_df = df.copy()\n",
    "    featurized_df = get_time_features(featurized_df)\n",
    "    return featurized_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = featurize_pipeline(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['date'] = data['date_time'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_indexes_timebased_validation(df: pd.DataFrame, dates: list):\n",
    "    \"\"\"\n",
    "    get validation splits\n",
    "    \"\"\"\n",
    "    last_index_train = df[df['date'] < dates[-2]].index.max()\n",
    "    last_index_val = df[df['date'] == dates[-2]].index.max()\n",
    "    return last_index_train, last_index_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_index_train, last_index_val = get_indexes_timebased_validation(data, dates=sorted(data.date.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data to model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "def _convert_to_ffm(path, df, type, target, numerics, categories, encoder):\n",
    "    # Flagging categorical and numerical fields\n",
    "    print('convert_to_ffm - START')\n",
    "    for x in numerics:\n",
    "        if(x not in encoder['catdict']):\n",
    "            encoder['catdict'][x] = 0\n",
    "    for x in categories:\n",
    "        if(x not in encoder['catdict']):\n",
    "            encoder['catdict'][x] = 1\n",
    "\n",
    "    nrows = df.shape[0]\n",
    "    with open(path + str(type) + \"_ffm.txt\", \"w\") as text_file:\n",
    "\n",
    "        # Looping over rows to convert each row to libffm format\n",
    "        for n, r in enumerate(range(nrows)):\n",
    "            datastring = \"\"\n",
    "            datarow = df.iloc[r].to_dict()\n",
    "            datastring += str(int(datarow[target]))  # Set Target Variable here\n",
    "\n",
    "            # For numerical fields, we are creating a dummy field here\n",
    "            for i, x in enumerate(encoder['catdict'].keys()):\n",
    "                if(encoder['catdict'][x] == 0):\n",
    "                    # Not adding numerical values that are nan\n",
    "                    if math.isnan(datarow[x]) is not True:\n",
    "                        datastring = datastring + \" \"+str(i)+\":\" + str(i)+\":\" + str(datarow[x])\n",
    "                else:\n",
    "\n",
    "                    # For a new field appearing in a training example\n",
    "                    if(x not in encoder['catcodes']):\n",
    "                        encoder['catcodes'][x] = {}\n",
    "                        encoder['currentcode'] += 1\n",
    "                        encoder['catcodes'][x][datarow[x]] = encoder['currentcode']  # encoding the feature\n",
    "\n",
    "                    # For already encoded fields\n",
    "                    elif(datarow[x] not in encoder['catcodes'][x]):\n",
    "                        encoder['currentcode'] += 1\n",
    "                        encoder['catcodes'][x][datarow[x]] = encoder['currentcode']  # encoding the feature\n",
    "\n",
    "                    code = encoder['catcodes'][x][datarow[x]]\n",
    "                    datastring = datastring + \" \"+str(i)+\":\" + str(int(code))+\":1\"\n",
    "\n",
    "            datastring += '\\n'\n",
    "            text_file.write(datastring)\n",
    "\n",
    "    # print('Encoder Summary:')\n",
    "    # print(json.dumps(encoder, indent=4))\n",
    "    return encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date_time', 'zone_id', 'banner_id', 'oaid_hash', 'campaign_clicks',\n",
       "       'os_id', 'country_id', 'clicks', 'hour', 'date'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select params for data transformation\n",
    "TARGET = ['clicks']\n",
    "NUMERICAL_FEATURES = ['campaign_clicks']\n",
    "CATEGORICAL_FEATURES = ['zone_id', 'banner_id', 'oaid_hash', 'os_id', 'country_id',  'hour']\n",
    "NUM_THREADS = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = {\"currentcode\": len(NUMERICAL_FEATURES),\n",
    "           \"catdict\": {},\n",
    "           \"catcodes\": {}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = TARGET + NUMERICAL_FEATURES + CATEGORICAL_FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = data.iloc[:last_index_train+1][FEATURES]\n",
    "val_df = data.iloc[last_index_train+1: last_index_val+1][FEATURES]\n",
    "test_df = data.iloc[last_index_val+1:][FEATURES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clicks</th>\n",
       "      <th>campaign_clicks</th>\n",
       "      <th>zone_id</th>\n",
       "      <th>banner_id</th>\n",
       "      <th>oaid_hash</th>\n",
       "      <th>os_id</th>\n",
       "      <th>country_id</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>29</td>\n",
       "      <td>1834033519797437404</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>188</td>\n",
       "      <td>7416450538971744701</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>52</td>\n",
       "      <td>1832228443297591417</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>73</td>\n",
       "      <td>4180077124914749282</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>266</td>\n",
       "      <td>1459689388363839798</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   clicks  campaign_clicks  zone_id  banner_id            oaid_hash  os_id  \\\n",
       "0       0                1       41         29  1834033519797437404      3   \n",
       "1       0                2        1        188  7416450538971744701      2   \n",
       "2       0                2       17         52  1832228443297591417      2   \n",
       "3       0                1       47         73  4180077124914749282      4   \n",
       "4       0                1       48        266  1459689388363839798      0   \n",
       "\n",
       "   country_id  hour  \n",
       "0           0     0  \n",
       "1          15     0  \n",
       "2           5     0  \n",
       "3          13     0  \n",
       "4           1     0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convert_to_ffm - START\n",
      "convert_to_ffm - START\n",
      "convert_to_ffm - START\n"
     ]
    }
   ],
   "source": [
    "#converte data to xlearn format\n",
    "\n",
    "encoder = _convert_to_ffm('data/', \n",
    "                          train_df,\n",
    "                         'train',\n",
    "                          TARGET[0],\n",
    "                          NUMERICAL_FEATURES,\n",
    "                          CATEGORICAL_FEATURES,\n",
    "                          encoder)\n",
    "\n",
    "encoder = _convert_to_ffm('data/', \n",
    "                          val_df,\n",
    "                         'val',\n",
    "                          TARGET[0],\n",
    "                          NUMERICAL_FEATURES,\n",
    "                          CATEGORICAL_FEATURES,\n",
    "                          encoder)\n",
    "\n",
    "encoder = _convert_to_ffm('data/', \n",
    "                          test_df,\n",
    "                         'test',\n",
    "                          TARGET[0],\n",
    "                          NUMERICAL_FEATURES,\n",
    "                          CATEGORICAL_FEATURES,\n",
    "                          encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current param = {'epoch': 30, 'k': 2, 'task': 'binary', 'lr': 0.1, 'lambda': 0.5}\n",
      "\u001b[32m\u001b[1m----------------------------------------------------------------------------------------------\n",
      "           _\n",
      "          | |\n",
      "     __  _| |     ___  __ _ _ __ _ __\n",
      "     \\ \\/ / |    / _ \\/ _` | '__| '_ \\ \n",
      "      >  <| |___|  __/ (_| | |  | | | |\n",
      "     /_/\\_\\_____/\\___|\\__,_|_|  |_| |_|\n",
      "\n",
      "        xLearn   -- 0.40 Version --\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[39m\u001b[0m\u001b[32m[------------] \u001b[0mxLearn uses 12 threads for training task.\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Read Problem ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (data/train_ffm.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (data/val_ffm.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mNumber of Feature: 5665387\n",
      "\u001b[32m[------------] \u001b[0mNumber of Field: 7\n",
      "\u001b[32m[------------] \u001b[0mTime cost for reading problem: 10.99 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Initialize model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mModel size: 1.22 GB\n",
      "\u001b[32m[------------] \u001b[0mTime cost for model initial: 0.98 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to train ...\u001b[0m\n",
      "\u001b[32m[------------]\u001b[0m Epoch      Train log_loss       Test log_loss     Time cost (sec)\n",
      "\u001b[32m[ \u001b[0m   3%\u001b[32m      ]\u001b[0m     1            0.109403            0.179159                5.54\n",
      "\u001b[32m[ \u001b[0m   6%\u001b[32m      ]\u001b[0m     2            0.108944            0.179149                5.54\n",
      "\u001b[32m[ \u001b[0m  10%\u001b[32m      ]\u001b[0m     3            0.108600            0.178412                6.01\n",
      "\u001b[32m[ \u001b[0m  13%\u001b[32m      ]\u001b[0m     4            0.108241            0.179266                5.30\n",
      "\u001b[32m[ \u001b[0m  16%\u001b[32m      ]\u001b[0m     5            0.108039            0.179171                5.78\n",
      "\u001b[32m[ \u001b[0m  20%\u001b[32m      ]\u001b[0m     6            0.107614            0.178850                5.20\n",
      "\u001b[32m[ \u001b[0m  23%\u001b[32m      ]\u001b[0m     7            0.107810            0.178001                5.38\n",
      "\u001b[32m[ \u001b[0m  26%\u001b[32m      ]\u001b[0m     8            0.107642            0.179331                5.55\n",
      "\u001b[32m[ \u001b[0m  30%\u001b[32m      ]\u001b[0m     9            0.107683            0.178171                5.82\n",
      "\u001b[32m[ \u001b[0m  33%\u001b[32m      ]\u001b[0m    10            0.106759            0.177727                5.56\n",
      "\u001b[32m[ \u001b[0m  36%\u001b[32m      ]\u001b[0m    11            0.107680            0.179315                6.12\n",
      "\u001b[32m[ \u001b[0m  40%\u001b[32m      ]\u001b[0m    12            0.107516            0.178576                5.64\n",
      "\u001b[32m[ \u001b[0m  43%\u001b[32m      ]\u001b[0m    13            0.106839            0.177791                6.14\n",
      "\u001b[32m[ \u001b[0m  46%\u001b[32m      ]\u001b[0m    14            0.106284            0.177460                5.31\n",
      "\u001b[32m[ \u001b[0m  50%\u001b[32m      ]\u001b[0m    15            0.106556            0.178530                5.65\n",
      "\u001b[32m[ \u001b[0m  53%\u001b[32m      ]\u001b[0m    16            0.107815            0.179380                5.76\n",
      "\u001b[32m[ \u001b[0m  56%\u001b[32m      ]\u001b[0m    17            0.107338            0.178994                5.92\n",
      "\u001b[32m[ \u001b[0m  60%\u001b[32m      ]\u001b[0m    18            0.106980            0.178425                5.91\n",
      "\u001b[32m[ \u001b[0m  63%\u001b[32m      ]\u001b[0m    19            0.106463            0.177848                6.16\n",
      "\u001b[32m[ \u001b[0m  66%\u001b[32m      ]\u001b[0m    20            0.106002            0.177637                6.02\n",
      "\u001b[32m[ \u001b[0m  70%\u001b[32m      ]\u001b[0m    21            0.105788            0.177224                5.98\n",
      "\u001b[32m[ \u001b[0m  73%\u001b[32m      ]\u001b[0m    22            0.105749            0.177239                5.85\n",
      "\u001b[32m[ \u001b[0m  76%\u001b[32m      ]\u001b[0m    23            0.106055            0.178308                5.76\n",
      "\u001b[32m[ \u001b[0m  80%\u001b[32m      ]\u001b[0m    24            0.107540            0.180349                5.37\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Early-stopping at epoch 21, best loss: 0.177224\u001b[0m\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to save model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mModel file: data/model_all_days.xlearn\n",
      "\u001b[32m[------------] \u001b[0mTime cost for saving model: 2.13 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Finish training\u001b[0m\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Clear the xLearn environment ...\u001b[0m\n",
      "['*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*']\u001b[32m\u001b[1m[------------] Total time cost: 153.50 (sec)\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param = {'epoch': 30,\n",
    "            'k': 2,\n",
    "            'task': 'binary',\n",
    "            'lr': 0.1,\n",
    "            'lambda': 0.5}\n",
    "print(f\"current param = {param}\")\n",
    "ffm_model = xl.create_ffm()\n",
    "ffm_model.setTrain(\"data/train_ffm.txt\")\n",
    "ffm_model.setValidate(\"data/val_ffm.txt\")\n",
    "ffm_model.fit(param, f\"data/model_all_days.xlearn\")\n",
    "print(['*'] * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train on previous day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process data and Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    get time features\n",
    "    \"\"\"\n",
    "    df['hour'] = df['date_time'].dt.hour\n",
    "    return df\n",
    "\n",
    "\n",
    "def featurize_pipeline(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    pipeline for the feature preparation\n",
    "    \"\"\"\n",
    "    featurized_df = df.copy()\n",
    "    featurized_df = get_time_features(featurized_df)\n",
    "    return featurized_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = featurize_pipeline(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = sorted(data.date.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data to model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "def _convert_to_ffm(path, df, type, target, numerics, categories, encoder):\n",
    "    # Flagging categorical and numerical fields\n",
    "    print('convert_to_ffm - START')\n",
    "    for x in numerics:\n",
    "        if(x not in encoder['catdict']):\n",
    "            encoder['catdict'][x] = 0\n",
    "    for x in categories:\n",
    "        if(x not in encoder['catdict']):\n",
    "            encoder['catdict'][x] = 1\n",
    "\n",
    "    nrows = df.shape[0]\n",
    "    with open(path + str(type) + \"_ffm.txt\", \"w\") as text_file:\n",
    "\n",
    "        # Looping over rows to convert each row to libffm format\n",
    "        for n, r in enumerate(range(nrows)):\n",
    "            datastring = \"\"\n",
    "            datarow = df.iloc[r].to_dict()\n",
    "            datastring += str(int(datarow[target]))  # Set Target Variable here\n",
    "\n",
    "            # For numerical fields, we are creating a dummy field here\n",
    "            for i, x in enumerate(encoder['catdict'].keys()):\n",
    "                if(encoder['catdict'][x] == 0):\n",
    "                    # Not adding numerical values that are nan\n",
    "                    if math.isnan(datarow[x]) is not True:\n",
    "                        datastring = datastring + \" \"+str(i)+\":\" + str(i)+\":\" + str(datarow[x])\n",
    "                else:\n",
    "\n",
    "                    # For a new field appearing in a training example\n",
    "                    if(x not in encoder['catcodes']):\n",
    "                        encoder['catcodes'][x] = {}\n",
    "                        encoder['currentcode'] += 1\n",
    "                        encoder['catcodes'][x][datarow[x]] = encoder['currentcode']  # encoding the feature\n",
    "\n",
    "                    # For already encoded fields\n",
    "                    elif(datarow[x] not in encoder['catcodes'][x]):\n",
    "                        encoder['currentcode'] += 1\n",
    "                        encoder['catcodes'][x][datarow[x]] = encoder['currentcode']  # encoding the feature\n",
    "\n",
    "                    code = encoder['catcodes'][x][datarow[x]]\n",
    "                    datastring = datastring + \" \"+str(i)+\":\" + str(int(code))+\":1\"\n",
    "\n",
    "            datastring += '\\n'\n",
    "            text_file.write(datastring)\n",
    "\n",
    "    # print('Encoder Summary:')\n",
    "    # print(json.dumps(encoder, indent=4))\n",
    "    return encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date_time', 'zone_id', 'banner_id', 'oaid_hash', 'campaign_clicks',\n",
       "       'os_id', 'country_id', 'clicks', 'hour', 'date'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select params for data transformation\n",
    "TARGET = ['clicks']\n",
    "NUMERICAL_FEATURES = ['campaign_clicks']\n",
    "CATEGORICAL_FEATURES = ['zone_id', 'banner_id', 'oaid_hash', 'os_id', 'country_id',  'hour']\n",
    "NUM_THREADS = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = {\"currentcode\": len(NUMERICAL_FEATURES),\n",
    "           \"catdict\": {},\n",
    "           \"catcodes\": {}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = TARGET + NUMERICAL_FEATURES + CATEGORICAL_FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Делать валидацию по дням с усреднением результатов слишком вычислительно дорого, поэтому так\n",
    "train_df = data[data.date==dates[-3]][FEATURES]\n",
    "val_df = data[data.date==dates[-2]][FEATURES]\n",
    "test_df = data[data.date==dates[-1]][FEATURES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clicks</th>\n",
       "      <th>campaign_clicks</th>\n",
       "      <th>zone_id</th>\n",
       "      <th>banner_id</th>\n",
       "      <th>oaid_hash</th>\n",
       "      <th>os_id</th>\n",
       "      <th>country_id</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10197856</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>52</td>\n",
       "      <td>1995762422249821197</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10197857</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>24</td>\n",
       "      <td>845498275380046131</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10197858</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>115</td>\n",
       "      <td>1439329130559143244</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10197859</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>1248052718144148612</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10197860</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>28</td>\n",
       "      <td>8031738334595892994</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          clicks  campaign_clicks  zone_id  banner_id            oaid_hash  \\\n",
       "10197856       0                0       17         52  1995762422249821197   \n",
       "10197857       0                0       14         24   845498275380046131   \n",
       "10197858       0                1       43        115  1439329130559143244   \n",
       "10197859       0                3       27          2  1248052718144148612   \n",
       "10197860       0                0       11         28  8031738334595892994   \n",
       "\n",
       "          os_id  country_id  hour  \n",
       "10197856      2           5     0  \n",
       "10197857      4           1     0  \n",
       "10197858      0          14     0  \n",
       "10197859      0           0     0  \n",
       "10197860      2           5     0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convert_to_ffm - START\n",
      "convert_to_ffm - START\n",
      "convert_to_ffm - START\n"
     ]
    }
   ],
   "source": [
    "#converte data to xlearn format\n",
    "\n",
    "encoder = _convert_to_ffm('data/', \n",
    "                          train_df,\n",
    "                         'prev_train',\n",
    "                          TARGET[0],\n",
    "                          NUMERICAL_FEATURES,\n",
    "                          CATEGORICAL_FEATURES,\n",
    "                          encoder)\n",
    "\n",
    "encoder = _convert_to_ffm('data/', \n",
    "                          val_df,\n",
    "                         'prev_val',\n",
    "                          TARGET[0],\n",
    "                          NUMERICAL_FEATURES,\n",
    "                          CATEGORICAL_FEATURES,\n",
    "                          encoder)\n",
    "\n",
    "encoder = _convert_to_ffm('data/', \n",
    "                          test_df,\n",
    "                         'prev_test',\n",
    "                          TARGET[0],\n",
    "                          NUMERICAL_FEATURES,\n",
    "                          CATEGORICAL_FEATURES,\n",
    "                          encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current param = {'epoch': 30, 'k': 2, 'task': 'binary', 'lr': 0.1, 'lambda': 0.5}\n",
      "\u001b[32m\u001b[1m----------------------------------------------------------------------------------------------\n",
      "           _\n",
      "          | |\n",
      "     __  _| |     ___  __ _ _ __ _ __\n",
      "     \\ \\/ / |    / _ \\/ _` | '__| '_ \\ \n",
      "      >  <| |___|  __/ (_| | |  | | | |\n",
      "     /_/\\_\\_____/\\___|\\__,_|_|  |_| |_|\n",
      "\n",
      "        xLearn   -- 0.40 Version --\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[39m\u001b[0m\u001b[32m[------------] \u001b[0mxLearn uses 12 threads for training task.\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Read Problem ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (data/prev_train_ffm.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (data/prev_val_ffm.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mNumber of Feature: 1706179\n",
      "\u001b[32m[------------] \u001b[0mNumber of Field: 7\n",
      "\u001b[32m[------------] \u001b[0mTime cost for reading problem: 2.56 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Initialize model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mModel size: 377.50 MB\n",
      "\u001b[32m[------------] \u001b[0mTime cost for model initial: 0.28 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to train ...\u001b[0m\n",
      "\u001b[32m[------------]\u001b[0m Epoch      Train log_loss       Test log_loss     Time cost (sec)\n",
      "\u001b[32m[ \u001b[0m   3%\u001b[32m      ]\u001b[0m     1            0.153831            0.173308                0.89\n",
      "\u001b[32m[ \u001b[0m   6%\u001b[32m      ]\u001b[0m     2            0.153036            0.173137                0.94\n",
      "\u001b[32m[ \u001b[0m  10%\u001b[32m      ]\u001b[0m     3            0.152497            0.173106                0.89\n",
      "\u001b[32m[ \u001b[0m  13%\u001b[32m      ]\u001b[0m     4            0.152042            0.173004                0.87\n",
      "\u001b[32m[ \u001b[0m  16%\u001b[32m      ]\u001b[0m     5            0.151673            0.173029                0.93\n",
      "\u001b[32m[ \u001b[0m  20%\u001b[32m      ]\u001b[0m     6            0.151369            0.173034                0.89\n",
      "\u001b[32m[ \u001b[0m  23%\u001b[32m      ]\u001b[0m     7            0.151077            0.173015                0.96\n",
      "\u001b[32m[ \u001b[0m  26%\u001b[32m      ]\u001b[0m     8            0.150839            0.172977                0.87\n",
      "\u001b[32m[ \u001b[0m  30%\u001b[32m      ]\u001b[0m     9            0.150610            0.172933                0.87\n",
      "\u001b[32m[ \u001b[0m  33%\u001b[32m      ]\u001b[0m    10            0.150374            0.172882                0.96\n",
      "\u001b[32m[ \u001b[0m  36%\u001b[32m      ]\u001b[0m    11            0.150214            0.172916                0.91\n",
      "\u001b[32m[ \u001b[0m  40%\u001b[32m      ]\u001b[0m    12            0.150020            0.172869                0.85\n",
      "\u001b[32m[ \u001b[0m  43%\u001b[32m      ]\u001b[0m    13            0.149932            0.172848                0.88\n",
      "\u001b[32m[ \u001b[0m  46%\u001b[32m      ]\u001b[0m    14            0.149759            0.172870                0.88\n",
      "\u001b[32m[ \u001b[0m  50%\u001b[32m      ]\u001b[0m    15            0.149641            0.172845                0.89\n",
      "\u001b[32m[ \u001b[0m  53%\u001b[32m      ]\u001b[0m    16            0.149494            0.172830                0.90\n",
      "\u001b[32m[ \u001b[0m  56%\u001b[32m      ]\u001b[0m    17            0.149450            0.172821                0.91\n",
      "\u001b[32m[ \u001b[0m  60%\u001b[32m      ]\u001b[0m    18            0.149249            0.172814                0.85\n",
      "\u001b[32m[ \u001b[0m  63%\u001b[32m      ]\u001b[0m    19            0.149236            0.172739                0.87\n",
      "\u001b[32m[ \u001b[0m  66%\u001b[32m      ]\u001b[0m    20            0.149078            0.172766                0.91\n",
      "\u001b[32m[ \u001b[0m  70%\u001b[32m      ]\u001b[0m    21            0.148980            0.172776                0.88\n",
      "\u001b[32m[ \u001b[0m  73%\u001b[32m      ]\u001b[0m    22            0.148962            0.172740                0.91\n",
      "\u001b[32m[ \u001b[0m  76%\u001b[32m      ]\u001b[0m    23            0.148892            0.172735                0.86\n",
      "\u001b[32m[ \u001b[0m  80%\u001b[32m      ]\u001b[0m    24            0.148727            0.172769                0.86\n",
      "\u001b[32m[ \u001b[0m  83%\u001b[32m      ]\u001b[0m    25            0.148712            0.172723                0.86\n",
      "\u001b[32m[ \u001b[0m  86%\u001b[32m      ]\u001b[0m    26            0.148661            0.172660                0.87\n",
      "\u001b[32m[ \u001b[0m  90%\u001b[32m      ]\u001b[0m    27            0.148589            0.172707                0.88\n",
      "\u001b[32m[ \u001b[0m  93%\u001b[32m      ]\u001b[0m    28            0.148446            0.172755                0.86\n",
      "\u001b[32m[ \u001b[0m  96%\u001b[32m      ]\u001b[0m    29            0.148400            0.172729                0.86\n",
      "\u001b[32m[ \u001b[0m 100%\u001b[32m      ]\u001b[0m    30            0.148393            0.172739                0.90\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Early-stopping at epoch 26, best loss: 0.172660\u001b[0m\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to save model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mModel file: data/model_prev.xlearn\n",
      "\u001b[32m[------------] \u001b[0mTime cost for saving model: 1.11 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Finish training\u001b[0m\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Clear the xLearn environment ...\u001b[0m\n",
      "['*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*']\u001b[32m\u001b[1m[------------] Total time cost: 31.70 (sec)\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# результаты выглядят гораздо адекватнее, чем при обучении на всех днях. Можно попробовать поиск гиперпараметров\n",
    "param = {'epoch': 30,\n",
    "            'k': 2,\n",
    "            'task': 'binary',\n",
    "            'lr': 0.1,\n",
    "            'lambda': 0.5}\n",
    "print(f\"current param = {param}\")\n",
    "ffm_model = xl.create_ffm()\n",
    "ffm_model.setTrain(\"data/prev_train_ffm.txt\")\n",
    "ffm_model.setValidate(\"data/prev_val_ffm.txt\")\n",
    "ffm_model.fit(param, f\"data/model_prev.xlearn\")\n",
    "print(['*'] * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# перебор небольшого кол-ва параметров, т.к. слишком долгий расчет\n",
    "params = {\n",
    "    'epoch': [40], # early stopping by default\n",
    "    'k': sorted(range(5, 11, 5)),\n",
    "    'task':['binary'],\n",
    "    'lr':[0.001, 0.01],\n",
    "    'lambda':[0.05],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current param = {'epoch': 40, 'k': 5, 'lambda': 0.05, 'lr': 0.001, 'task': 'binary'} and id=0\n",
      "\u001b[32m\u001b[1m----------------------------------------------------------------------------------------------\n",
      "           _\n",
      "          | |\n",
      "     __  _| |     ___  __ _ _ __ _ __\n",
      "     \\ \\/ / |    / _ \\/ _` | '__| '_ \\ \n",
      "      >  <| |___|  __/ (_| | |  | | | |\n",
      "     /_/\\_\\_____/\\___|\\__,_|_|  |_| |_|\n",
      "\n",
      "        xLearn   -- 0.40 Version --\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[39m\u001b[0m\u001b[32m[------------] \u001b[0mxLearn uses 12 threads for training task.\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Read Problem ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (data/prev_train_ffm.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (data/prev_val_ffm.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mNumber of Feature: 1706179\n",
      "\u001b[32m[------------] \u001b[0mNumber of Field: 7\n",
      "\u001b[32m[------------] \u001b[0mTime cost for reading problem: 2.35 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Initialize model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mModel size: 741.98 MB\n",
      "\u001b[32m[------------] \u001b[0mTime cost for model initial: 0.54 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to train ...\u001b[0m\n",
      "\u001b[32m[------------]\u001b[0m Epoch      Train log_loss       Test log_loss     Time cost (sec)\n",
      "\u001b[32m[ \u001b[0m   2%\u001b[32m      ]\u001b[0m     1            0.259736            0.207272                1.02\n",
      "\u001b[32m[ \u001b[0m   5%\u001b[32m      ]\u001b[0m     2            0.182161            0.189140                0.83\n",
      "\u001b[32m[ \u001b[0m   7%\u001b[32m      ]\u001b[0m     3            0.169989            0.182681                0.86\n",
      "\u001b[32m[ \u001b[0m  10%\u001b[32m      ]\u001b[0m     4            0.165708            0.180292                0.82\n",
      "\u001b[32m[ \u001b[0m  12%\u001b[32m      ]\u001b[0m     5            0.162831            0.177659                0.82\n",
      "\u001b[32m[ \u001b[0m  15%\u001b[32m      ]\u001b[0m     6            0.161291            0.177766                0.79\n",
      "\u001b[32m[ \u001b[0m  17%\u001b[32m      ]\u001b[0m     7            0.162030            0.178563                0.78\n",
      "\u001b[32m[ \u001b[0m  20%\u001b[32m      ]\u001b[0m     8            0.163233            0.179669                0.77\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Early-stopping at epoch 5, best loss: 0.177659\u001b[0m\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to save model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mModel file: data/model_prev_0.xlearn\n",
      "\u001b[32m[------------] \u001b[0mTime cost for saving model: 1.62 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Finish training\u001b[0m\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Clear the xLearn environment ...\u001b[0m\n",
      "['*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*']\u001b[32m\u001b[1m[------------] Total time cost: 12.22 (sec)\u001b[0m\n",
      "\n",
      "current param = {'epoch': 40, 'k': 5, 'lambda': 0.05, 'lr': 0.01, 'task': 'binary'} and id=1\n",
      "\u001b[32m\u001b[1m----------------------------------------------------------------------------------------------\n",
      "           _\n",
      "          | |\n",
      "     __  _| |     ___  __ _ _ __ _ __\n",
      "     \\ \\/ / |    / _ \\/ _` | '__| '_ \\ \n",
      "      >  <| |___|  __/ (_| | |  | | | |\n",
      "     /_/\\_\\_____/\\___|\\__,_|_|  |_| |_|\n",
      "\n",
      "        xLearn   -- 0.40 Version --\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[39m\u001b[0m\u001b[32m[------------] \u001b[0mxLearn uses 12 threads for training task.\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Read Problem ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (data/prev_train_ffm.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (data/prev_val_ffm.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mNumber of Feature: 1706179\n",
      "\u001b[32m[------------] \u001b[0mNumber of Field: 7\n",
      "\u001b[32m[------------] \u001b[0mTime cost for reading problem: 2.18 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Initialize model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mModel size: 741.98 MB\n",
      "\u001b[32m[------------] \u001b[0mTime cost for model initial: 0.50 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to train ...\u001b[0m\n",
      "\u001b[32m[------------]\u001b[0m Epoch      Train log_loss       Test log_loss     Time cost (sec)\n",
      "\u001b[32m[ \u001b[0m   2%\u001b[32m      ]\u001b[0m     1            0.154150            0.170077                0.81\n",
      "\u001b[32m[ \u001b[0m   5%\u001b[32m      ]\u001b[0m     2            0.150043            0.169863                0.92\n",
      "\u001b[32m[ \u001b[0m   7%\u001b[32m      ]\u001b[0m     3            0.149694            0.169781                0.95\n",
      "\u001b[32m[ \u001b[0m  10%\u001b[32m      ]\u001b[0m     4            0.149480            0.169661                1.04\n",
      "\u001b[32m[ \u001b[0m  12%\u001b[32m      ]\u001b[0m     5            0.149343            0.169736                0.88\n",
      "\u001b[32m[ \u001b[0m  15%\u001b[32m      ]\u001b[0m     6            0.149233            0.169632                0.93\n",
      "\u001b[32m[ \u001b[0m  17%\u001b[32m      ]\u001b[0m     7            0.149125            0.169398                0.92\n",
      "\u001b[32m[ \u001b[0m  20%\u001b[32m      ]\u001b[0m     8            0.149052            0.169292                0.84\n",
      "\u001b[32m[ \u001b[0m  22%\u001b[32m      ]\u001b[0m     9            0.148982            0.169259                0.84\n",
      "\u001b[32m[ \u001b[0m  25%\u001b[32m      ]\u001b[0m    10            0.148898            0.169322                0.83\n",
      "\u001b[32m[ \u001b[0m  27%\u001b[32m      ]\u001b[0m    11            0.148818            0.169501                0.82\n",
      "\u001b[32m[ \u001b[0m  30%\u001b[32m      ]\u001b[0m    12            0.148780            0.169752                0.88\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Early-stopping at epoch 9, best loss: 0.169259\u001b[0m\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to save model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mModel file: data/model_prev_1.xlearn\n",
      "\u001b[32m[------------] \u001b[0mTime cost for saving model: 1.59 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Finish training\u001b[0m\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Clear the xLearn environment ...\u001b[0m\n",
      "['*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*']\u001b[32m\u001b[1m[------------] Total time cost: 16.23 (sec)\u001b[0m\n",
      "\n",
      "current param = {'epoch': 40, 'k': 10, 'lambda': 0.05, 'lr': 0.001, 'task': 'binary'} and id=2\n",
      "\u001b[32m\u001b[1m----------------------------------------------------------------------------------------------\n",
      "           _\n",
      "          | |\n",
      "     __  _| |     ___  __ _ _ __ _ __\n",
      "     \\ \\/ / |    / _ \\/ _` | '__| '_ \\ \n",
      "      >  <| |___|  __/ (_| | |  | | | |\n",
      "     /_/\\_\\_____/\\___|\\__,_|_|  |_| |_|\n",
      "\n",
      "        xLearn   -- 0.40 Version --\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[39m\u001b[0m\u001b[32m[------------] \u001b[0mxLearn uses 12 threads for training task.\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Read Problem ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (data/prev_train_ffm.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (data/prev_val_ffm.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mNumber of Feature: 1706179\n",
      "\u001b[32m[------------] \u001b[0mNumber of Field: 7\n",
      "\u001b[32m[------------] \u001b[0mTime cost for reading problem: 2.61 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Initialize model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mModel size: 1.08 GB\n",
      "\u001b[32m[------------] \u001b[0mTime cost for model initial: 0.99 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to train ...\u001b[0m\n",
      "\u001b[32m[------------]\u001b[0m Epoch      Train log_loss       Test log_loss     Time cost (sec)\n",
      "\u001b[32m[ \u001b[0m   2%\u001b[32m      ]\u001b[0m     1            0.258352            0.206553                1.05\n",
      "\u001b[32m[ \u001b[0m   5%\u001b[32m      ]\u001b[0m     2            0.181668            0.188656                1.09\n",
      "\u001b[32m[ \u001b[0m   7%\u001b[32m      ]\u001b[0m     3            0.169683            0.182536                1.04\n",
      "\u001b[32m[ \u001b[0m  10%\u001b[32m      ]\u001b[0m     4            0.165563            0.180145                1.05\n",
      "\u001b[32m[ \u001b[0m  12%\u001b[32m      ]\u001b[0m     5            0.162655            0.177744                1.00\n",
      "\u001b[32m[ \u001b[0m  15%\u001b[32m      ]\u001b[0m     6            0.161578            0.178067                1.09\n",
      "\u001b[32m[ \u001b[0m  17%\u001b[32m      ]\u001b[0m     7            0.162438            0.178968                1.05\n",
      "\u001b[32m[ \u001b[0m  20%\u001b[32m      ]\u001b[0m     8            0.163781            0.180157                0.98\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Early-stopping at epoch 5, best loss: 0.177744\u001b[0m\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to save model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[------------] \u001b[0mModel file: data/model_prev_2.xlearn\n",
      "\u001b[32m[------------] \u001b[0mTime cost for saving model: 2.11 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Finish training\u001b[0m\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Clear the xLearn environment ...\u001b[0m\n",
      "['*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*']\u001b[32m\u001b[1m[------------] Total time cost: 15.67 (sec)\u001b[0m\n",
      "\n",
      "current param = {'epoch': 40, 'k': 10, 'lambda': 0.05, 'lr': 0.01, 'task': 'binary'} and id=3\n",
      "\u001b[32m\u001b[1m----------------------------------------------------------------------------------------------\n",
      "           _\n",
      "          | |\n",
      "     __  _| |     ___  __ _ _ __ _ __\n",
      "     \\ \\/ / |    / _ \\/ _` | '__| '_ \\ \n",
      "      >  <| |___|  __/ (_| | |  | | | |\n",
      "     /_/\\_\\_____/\\___|\\__,_|_|  |_| |_|\n",
      "\n",
      "        xLearn   -- 0.40 Version --\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[39m\u001b[0m\u001b[32m[------------] \u001b[0mxLearn uses 12 threads for training task.\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Read Problem ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (data/prev_train_ffm.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (data/prev_val_ffm.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mNumber of Feature: 1706179\n",
      "\u001b[32m[------------] \u001b[0mNumber of Field: 7\n",
      "\u001b[32m[------------] \u001b[0mTime cost for reading problem: 2.24 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Initialize model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mModel size: 1.08 GB\n",
      "\u001b[32m[------------] \u001b[0mTime cost for model initial: 1.15 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to train ...\u001b[0m\n",
      "\u001b[32m[------------]\u001b[0m Epoch      Train log_loss       Test log_loss     Time cost (sec)\n",
      "\u001b[32m[ \u001b[0m   2%\u001b[32m      ]\u001b[0m     1            0.154030            0.170105                1.14\n",
      "\u001b[32m[ \u001b[0m   5%\u001b[32m      ]\u001b[0m     2            0.150052            0.169841                1.11\n",
      "\u001b[32m[ \u001b[0m   7%\u001b[32m      ]\u001b[0m     3            0.149678            0.169788                0.99\n",
      "\u001b[32m[ \u001b[0m  10%\u001b[32m      ]\u001b[0m     4            0.149489            0.169653                1.02\n",
      "\u001b[32m[ \u001b[0m  12%\u001b[32m      ]\u001b[0m     5            0.149342            0.169693                1.03\n",
      "\u001b[32m[ \u001b[0m  15%\u001b[32m      ]\u001b[0m     6            0.149229            0.169607                1.10\n",
      "\u001b[32m[ \u001b[0m  17%\u001b[32m      ]\u001b[0m     7            0.149114            0.169401                1.09\n",
      "\u001b[32m[ \u001b[0m  20%\u001b[32m      ]\u001b[0m     8            0.149046            0.169290                1.03\n",
      "\u001b[32m[ \u001b[0m  22%\u001b[32m      ]\u001b[0m     9            0.148978            0.169234                1.01\n",
      "\u001b[32m[ \u001b[0m  25%\u001b[32m      ]\u001b[0m    10            0.148902            0.169301                1.07\n",
      "\u001b[32m[ \u001b[0m  27%\u001b[32m      ]\u001b[0m    11            0.148809            0.169497                1.02\n",
      "\u001b[32m[ \u001b[0m  30%\u001b[32m      ]\u001b[0m    12            0.148769            0.169750                1.14\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Early-stopping at epoch 9, best loss: 0.169234\u001b[0m\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to save model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mModel file: data/model_prev_3.xlearn\n",
      "\u001b[32m[------------] \u001b[0mTime cost for saving model: 2.35 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Finish training\u001b[0m\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Clear the xLearn environment ...\u001b[0m\n",
      "['*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*']\u001b[32m\u001b[1m[------------] Total time cost: 20.53 (sec)\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for id, param in enumerate(ParameterGrid(params)):\n",
    "    print(f\"current param = {param} and id={id}\")\n",
    "    ffm_model = xl.create_ffm()\n",
    "    ffm_model.setTrain(\"data/prev_train_ffm.txt\")\n",
    "    ffm_model.setValidate(\"data/prev_val_ffm.txt\")\n",
    "    ffm_model.fit(param, f\"data/model_prev_{id}.xlearn\")\n",
    "    print(['*'] * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refit model with the best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m----------------------------------------------------------------------------------------------\n",
      "           _\n",
      "          | |\n",
      "     __  _| |     ___  __ _ _ __ _ __\n",
      "     \\ \\/ / |    / _ \\/ _` | '__| '_ \\ \n",
      "      >  <| |___|  __/ (_| | |  | | | |\n",
      "     /_/\\_\\_____/\\___|\\__,_|_|  |_| |_|\n",
      "\n",
      "        xLearn   -- 0.40 Version --\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[39m\u001b[0m\u001b[35m\u001b[1m[ WARNING    ] Validation file not found, xLearn has already disable early-stopping.\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mxLearn uses 12 threads for training task.\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Read Problem ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (data/prev_val_ffm.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mNumber of Feature: 1706179\n",
      "\u001b[32m[------------] \u001b[0mNumber of Field: 7\n",
      "\u001b[32m[------------] \u001b[0mTime cost for reading problem: 1.12 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Initialize model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mModel size: 1.08 GB\n",
      "\u001b[32m[------------] \u001b[0mTime cost for model initial: 0.90 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to train ...\u001b[0m\n",
      "\u001b[32m[------------]\u001b[0m Epoch      Train log_loss     Time cost (sec)\n",
      "\u001b[32m[ \u001b[0m  11%\u001b[32m      ]\u001b[0m     1            0.171707                0.66\n",
      "\u001b[32m[ \u001b[0m  22%\u001b[32m      ]\u001b[0m     2            0.167226                0.64\n",
      "\u001b[32m[ \u001b[0m  33%\u001b[32m      ]\u001b[0m     3            0.166768                0.63\n",
      "\u001b[32m[ \u001b[0m  44%\u001b[32m      ]\u001b[0m     4            0.166483                0.68\n",
      "\u001b[32m[ \u001b[0m  55%\u001b[32m      ]\u001b[0m     5            0.166256                0.70\n",
      "\u001b[32m[ \u001b[0m  66%\u001b[32m      ]\u001b[0m     6            0.166108                0.75\n",
      "\u001b[32m[ \u001b[0m  77%\u001b[32m      ]\u001b[0m     7            0.165967                0.73\n",
      "\u001b[32m[ \u001b[0m  88%\u001b[32m      ]\u001b[0m     8            0.165852                0.65\n",
      "\u001b[32m[ \u001b[0m 100%\u001b[32m      ]\u001b[0m     9            0.165739                0.64\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to save model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mModel file: data/model.xlearn\n",
      "\u001b[32m[------------] \u001b[0mTime cost for saving model: 1.41 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Finish training\u001b[0m\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Clear the xLearn environment ...\u001b[0m\n",
      "\u001b[32m\u001b[1m[------------] Total time cost: 9.56 (sec)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "best_params = {'epoch': 9, 'k': 10, 'lambda': 0.05, 'lr': 0.01, 'task': 'binary'}\n",
    "ffm_model = xl.create_ffm()\n",
    "ffm_model.setTrain(\"data/prev_val_ffm.txt\")\n",
    "ffm_model.fit(best_params, 'data/model.xlearn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffm_model.setTest(\"data/prev_test_ffm.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m----------------------------------------------------------------------------------------------\n",
      "           _\n",
      "          | |\n",
      "     __  _| |     ___  __ _ _ __ _ __\n",
      "     \\ \\/ / |    / _ \\/ _` | '__| '_ \\ \n",
      "      >  <| |___|  __/ (_| | |  | | | |\n",
      "     /_/\\_\\_____/\\___|\\__,_|_|  |_| |_|\n",
      "\n",
      "        xLearn   -- 0.40 Version --\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[39m\u001b[0m\u001b[32m[------------] \u001b[0mxLearn uses 12 threads for prediction task.\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Load model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mLoad model from data/model.xlearn\n",
      "\u001b[32m[------------] \u001b[0mLoss function: cross-entropy\n",
      "\u001b[32m[------------] \u001b[0mScore function: ffm\n",
      "\u001b[32m[------------] \u001b[0mNumber of Feature: 1706179\n",
      "\u001b[32m[------------] \u001b[0mNumber of K: 10\n",
      "\u001b[32m[------------] \u001b[0mNumber of field: 7\n",
      "\u001b[32m[------------] \u001b[0mTime cost for loading model: 0.57 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Read Problem ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (data/prev_test_ffm.txt.bin) NOT found. Convert text file to binary file.\n",
      "\u001b[32m[------------] \u001b[0mTime cost for reading problem: 3.14 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to predict ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mThe test loss is: 0.148402\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Clear the xLearn environment ...\u001b[0m\n",
      "\u001b[32m\u001b[1m[------------] Total time cost: 4.42 (sec)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "ffm_model.predict(\"data/model.xlearn\", \"predict.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c573e46ebead58db36569680cc0ab268342f230bf4121c93a3b85d9337ecfb20"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
